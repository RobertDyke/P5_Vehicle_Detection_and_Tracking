# Vehicle_Detection_and_Tracking_P5
Detects and tracks other vehicles.

By far the most complex project to date. A large data set of car images and non car images are used to train a neural net. HOGs (Histogram of Oriented Gradients) are created of both sets in multiple color schemes. A classifier is built and trained using the HOG data. Individual images are divided into "windows" that are run thru the classifier to identify them as either car or "not car". The windows identified as cars are then subject to a "heat map" that helps flush out single erroneous windows. At the end of the code a video is processed to identify cars near the drivers car.

The first cell defines the main HOG functions. Note that many color conversion schemes are used to convert the input image from RGB to others. The second cell tests a short video. The input is project_viedo.mp4 and the output is short.mp4. Cell 3 are functions to process single images. The forth cell computes the number of test images that are vehicles and not vehicles. A sample of each is shown after cell 4.

Cell 5 is the first really interesting output. Random images are printed along with their various HOGs. Note that some HOGs are better than others for this classification. Later I choose to use the HLS HOG as it seemed to be the best fit. The following two cells train the classifier.

Next a "slideing window" is built. A window is a very small section of the image. In this case 64 X 64 pixels. A grid of windows is built (see image of grid at end of cell). The next part can be confusing. Even though the window is 64 X 64, we shift right by only 32 pixels before getting the next window. So there is a 50% overlap from one image to the next. We do this as we can not count on luck to place a car centered in a window. After all of the windows for one row are taken, we go back to the far left an drop down 32 pixels for the same reason. (Look at the image of the grid. It really is easier to understand with visuals.)

In cell 12 the windows are searched for car features. Now, there is this kludged concept of "heat". It has nothing to do with things being hot. It is called heat because the output looks like a heat map. Each time a car is identified (correctly or not) a little box is added to the image. As more boxes are added it gets "hotter". Hotter more persistant parts of the image have greater and greater chances of actually containing cars. 
